{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a174f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Collecting torch==2.7.1\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torch-2.7.1%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (1039.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 GB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/lib/python3/dist-packages (0.22.0)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torchaudio-2.7.1%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.2.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl (260.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.4/260.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.7.1) (3.6.0)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.57\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.57\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.3.14\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl (609.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.6/609.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.3.1\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.8.61\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.2/39.2 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.7.53\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (292.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.3.41\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.9.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/lib/python3/dist-packages (from torch==2.7.1) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.7.1) (3.0.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.13.0.11\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.8.61\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch==2.7.1) (2.4)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /usr/lib/python3/dist-packages (from torch==2.7.1) (4.10.0)\n",
      "Collecting nvidia-cudnn-cu12==9.7.1.26\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl (726.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m726.9/726.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch==2.7.1) (59.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.8.3.14 nvidia-cuda-cupti-cu12-12.8.57 nvidia-cuda-nvrtc-cu12-12.8.61 nvidia-cuda-runtime-cu12-12.8.57 nvidia-cudnn-cu12-9.7.1.26 nvidia-cufft-cu12-11.3.3.41 nvidia-cufile-cu12-1.13.0.11 nvidia-curand-cu12-10.3.9.55 nvidia-cusolver-cu12-11.7.2.55 nvidia-cusparse-cu12-12.5.7.53 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.8.61 nvidia-nvtx-cu12-12.8.55 sympy-1.13.3 torch-2.7.1+cu128 torchaudio-2.7.1+cu128 triton-3.3.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (59.6.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools, pip\n",
      "Successfully installed pip-25.2 setuptools-80.9.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorrt_llm\n",
      "  Downloading tensorrt_llm-0.20.0.tar.gz (1.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate>=0.25.0 (from tensorrt_llm)\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting build (from tensorrt_llm)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting colored (from tensorrt_llm)\n",
      "  Downloading colored-2.3.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting cuda-python (from tensorrt_llm)\n",
      "  Downloading cuda_python-12.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting diffusers>=0.27.0 (from tensorrt_llm)\n",
      "  Downloading diffusers-0.34.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm) (1.2.2)\n",
      "Collecting mpi4py (from tensorrt_llm)\n",
      "  Downloading mpi4py-4.1.0-cp310-cp310-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy<2 in /usr/lib/python3/dist-packages (from tensorrt_llm) (1.21.5)\n",
      "Collecting onnx>=1.12.0 (from tensorrt_llm)\n",
      "  Downloading onnx-1.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting onnx_graphsurgeon>=0.5.2 (from tensorrt_llm)\n",
      "  Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting openai (from tensorrt_llm)\n",
      "  Downloading openai-1.98.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting polygraphy (from tensorrt_llm)\n",
      "  Downloading polygraphy-0.49.26-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from tensorrt_llm) (5.9.0)\n",
      "Requirement already satisfied: nvidia-ml-py>=12 in /usr/lib/python3/dist-packages (from tensorrt_llm) (12.555.43)\n",
      "Collecting pynvml>=12.0.0 (from tensorrt_llm)\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pulp (from tensorrt_llm)\n",
      "  Downloading pulp-3.2.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from tensorrt_llm) (1.3.5)\n",
      "Collecting h5py==3.12.1 (from tensorrt_llm)\n",
      "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting StrEnum (from tensorrt_llm)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting sentencepiece>=0.1.99 (from tensorrt_llm)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tensorrt~=10.10.0 (from tensorrt_llm)\n",
      "  Downloading tensorrt-10.10.0.31.tar.gz (40 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch<=2.7.0,>=2.7.0a0 (from tensorrt_llm)\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (from tensorrt_llm) (0.22.0)\n",
      "Collecting nvidia-modelopt~=0.29.0 (from nvidia-modelopt[torch]~=0.29.0->tensorrt_llm)\n",
      "  Downloading nvidia_modelopt-0.29.0-py3-none-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in ./.local/lib/python3.10/site-packages (from tensorrt_llm) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12 in ./.local/lib/python3.10/site-packages (from tensorrt_llm) (12.8.61)\n",
      "Collecting transformers~=4.51.1 (from tensorrt_llm)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pydantic>=2.9.1 (from tensorrt_llm)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pillow==10.3.0 (from tensorrt_llm)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<=0.45.1 in /usr/lib/python3/dist-packages (from tensorrt_llm) (0.37.1)\n",
      "Collecting optimum (from tensorrt_llm)\n",
      "  Downloading optimum-1.27.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets==3.1.0 (from tensorrt_llm)\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting evaluate (from tensorrt_llm)\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: mpmath>=1.3.0 in ./.local/lib/python3.10/site-packages (from tensorrt_llm) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorrt_llm) (8.0.3)\n",
      "Collecting click_option_group (from tensorrt_llm)\n",
      "  Downloading click_option_group-0.5.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aenum (from tensorrt_llm)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm) (27.0.0)\n",
      "Collecting fastapi==0.115.4 (from tensorrt_llm)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn (from tensorrt_llm)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting setuptools<80 (from tensorrt_llm)\n",
      "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting ordered-set (from tensorrt_llm)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting peft (from tensorrt_llm)\n",
      "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting einops (from tensorrt_llm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting flashinfer-python==0.2.5 (from tensorrt_llm)\n",
      "  Downloading flashinfer_python-0.2.5.tar.gz (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m199.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv-python-headless (from tensorrt_llm)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting xgrammar==0.1.16 (from tensorrt_llm)\n",
      "  Downloading xgrammar-0.1.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting backoff (from tensorrt_llm)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nvtx (from tensorrt_llm)\n",
      "  Downloading nvtx-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from tensorrt_llm) (3.5.1)\n",
      "Requirement already satisfied: h11>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm) (0.16.0)\n",
      "Requirement already satisfied: tornado>=6.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm) (6.5.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets==3.1.0->tensorrt_llm) (3.6.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->tensorrt_llm) (2.32.4)\n",
      "Collecting tqdm>=4.66.3 (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/lib/python3/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0->tensorrt_llm) (2024.3.1)\n",
      "Collecting aiohttp (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->tensorrt_llm) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets==3.1.0->tensorrt_llm) (5.4.1)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi==0.115.4->tensorrt_llm)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from fastapi==0.115.4->tensorrt_llm) (4.10.0)\n",
      "Collecting ninja (from flashinfer-python==0.2.5->tensorrt_llm)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting tiktoken (from xgrammar==0.1.16->tensorrt_llm)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting nvidia-modelopt-core==0.29.0 (from nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm)\n",
      "  Downloading nvidia_modelopt_core-0.29.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (847 bytes)\n",
      "Requirement already satisfied: rich in /usr/lib/python3/dist-packages (from nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm) (11.2.0)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm) (1.8.0)\n",
      "Collecting regex (from nvidia-modelopt[torch]~=0.29.0->tensorrt_llm)\n",
      "  Downloading regex-2025.7.34-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors (from nvidia-modelopt[torch]~=0.29.0->tensorrt_llm)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting torchprofile>=0.0.4 (from nvidia-modelopt[torch]~=0.29.0->tensorrt_llm)\n",
      "  Downloading torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.1->tensorrt_llm)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.1->tensorrt_llm)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi==0.115.4->tensorrt_llm)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.1->tensorrt_llm)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm) (1.3.1)\n",
      "Collecting tensorrt_cu12==10.10.0.31 (from tensorrt~=10.10.0->tensorrt_llm)\n",
      "  Downloading tensorrt_cu12-10.10.0.31.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt_cu12_libs==10.10.0.31 (from tensorrt_cu12==10.10.0.31->tensorrt~=10.10.0->tensorrt_llm)\n",
      "  Downloading tensorrt_cu12_libs-10.10.0.31.tar.gz (708 bytes)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt_cu12_bindings==10.10.0.31 (from tensorrt_cu12==10.10.0.31->tensorrt~=10.10.0->tensorrt_llm)\n",
      "  Downloading tensorrt_cu12_bindings-10.10.0.31-cp310-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in ./.local/lib/python3.10/site-packages (from tensorrt_cu12_libs==10.10.0.31->tensorrt_cu12==10.10.0.31->tensorrt~=10.10.0->tensorrt_llm) (12.8.57)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.local/lib/python3.10/site-packages (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm) (3.0.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12 (from tensorrt_llm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12 (from tensorrt_cu12_libs==10.10.0.31->tensorrt_cu12==10.10.0.31->tensorrt~=10.10.0->tensorrt_llm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.local/lib/python3.10/site-packages (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm) (0.6.3)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch<=2.7.0,>=2.7.0a0->tensorrt_llm)\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers~=4.51.1->tensorrt_llm)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.23.0->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->tensorrt_llm) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: importlib_metadata in /usr/lib/python3/dist-packages (from diffusers>=0.27.0->tensorrt_llm) (4.6.4)\n",
      "Collecting numpy<2 (from tensorrt_llm)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting protobuf>=4.25.1 (from onnx>=1.12.0->tensorrt_llm)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm) (2020.6.20)\n",
      "Collecting pyproject_hooks (from build->tensorrt_llm)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->tensorrt_llm) (2.2.1)\n",
      "Collecting cuda-bindings~=12.9.0 (from cuda-python->tensorrt_llm)\n",
      "  Downloading cuda_bindings-12.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->tensorrt_llm) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->tensorrt_llm) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->tensorrt_llm)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->tensorrt_llm) (1.0.9)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless (from tensorrt_llm)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/lib/python3/dist-packages (from rich->nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm) (0.4.4)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/lib/python3/dist-packages (from rich->nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/lib/python3/dist-packages (from rich->nvidia-modelopt~=0.29.0->nvidia-modelopt[torch]~=0.29.0->tensorrt_llm) (2.11.2)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m151.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading nvidia_modelopt-0.29.0-py3-none-manylinux_2_28_x86_64.whl (690 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.1/690.1 kB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_modelopt_core-0.29.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tensorrt_cu12_bindings-10.10.0.31-cp310-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m370.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m328.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m359.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m282.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m385.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m366.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m408.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m440.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m377.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m200.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m193.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m249.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m258.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m181.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading diffusers-0.34.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading onnx-1.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m199.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2025.7.34-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.8/789.8 kB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m154.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading click_option_group-0.5.7-py3-none-any.whl (11 kB)\n",
      "Downloading colored-2.3.1-py3-none-any.whl (19 kB)\n",
      "Downloading cuda_python-12.9.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading cuda_bindings-12.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "Downloading mpi4py-4.1.0-cp310-cp310-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m153.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading nvtx-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (473 kB)\n",
      "Downloading openai-1.98.0-py3-none-any.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.7/767.7 kB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading optimum-1.27.0-py3-none-any.whl (425 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Downloading polygraphy-0.49.26-py2.py3-none-any.whl (372 kB)\n",
      "Downloading pulp-3.2.2-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m168.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Building wheels for collected packages: tensorrt_llm, flashinfer-python, tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
      "  Building wheel for tensorrt_llm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_llm: filename=tensorrt_llm-0.20.0-cp310-cp310-linux_x86_64.whl size=3705064175 sha256=07c0eb825bf860b6793ec6839b4ad703857e79b8cff6aee8bca97e859ab74cac\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/bb/52/51/7380dedc6c63f1d108eda2c00c85f2205a4f1b279435922dd7\n",
      "  Building wheel for flashinfer-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashinfer-python: filename=flashinfer_python-0.2.5-py3-none-any.whl size=4124482 sha256=357e553ffd96f5d9be7e2f80701001d356b33d119a9431eb76eb6ca62ae21a11\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/04/8a/a1/1b2b48a9c798e867cc804d16cc5561de45aafc8dda004abcf2\n",
      "\u001b[33m  DEPRECATION: Building 'tensorrt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tensorrt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for tensorrt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.10.0.31-py2.py3-none-any.whl size=46732 sha256=15656822eebb2e2a9066d5f16437fb60312ff3354fd5bb8906c072e14bd99f98\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/a2/88/33/22af7edc2bba64e8665cc26dbab0565061a47dcc9ca855ef55\n",
      "\u001b[33m  DEPRECATION: Building 'tensorrt_cu12' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tensorrt_cu12'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.10.0.31-py2.py3-none-any.whl size=17581 sha256=a0ac24fab08a134b0977e31b42a523bfd7718eafeeb87b27b96cf5e27f255b70\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/27/69/8d/2a3811025d28733bfee9c0063a408b45b60183f84c333d8f2c\n",
      "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.10.0.31-py2.py3-none-manylinux_2_28_x86_64.whl size=3404991480 sha256=02a17ce9d84979d325a085e6492cfb71fae1039d4e7f55efe4de8e96d0410255\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/c5/1b/f1/543bf522ae00afc488174917e6c1edcbd7c97c7ea90013cadc\n",
      "Successfully built tensorrt_llm flashinfer-python tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
      "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorrt_cu12_bindings, StrEnum, sentencepiece, nvtx, cuda-bindings, aenum, xxhash, typing-extensions, tqdm, setuptools, safetensors, regex, pyproject_hooks, pynvml, pyarrow, pulp, protobuf, propcache, polygraphy, pillow, ordered-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-modelopt-core, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, mpi4py, jiter, hf-xet, frozenlist, einops, dill, cuda-python, colored, click_option_group, backoff, async-timeout, annotated-types, aiohappyeyeballs, uvicorn, typing-inspection, triton, tiktoken, tensorrt_cu12_libs, pydantic-core, opencv-python-headless, onnx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, multidict, huggingface-hub, h5py, build, aiosignal, yarl, tokenizers, tensorrt_cu12, pydantic, onnx_graphsurgeon, nvidia-cusolver-cu12, diffusers, transformers, torch, tensorrt, starlette, nvidia-modelopt, aiohttp, xgrammar, torchprofile, optimum, openai, flashinfer-python, fastapi, accelerate, peft, datasets, evaluate, tensorrt_llm\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [tqdm]bindings]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [tqdm]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]phy]]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.55━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.55:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.55━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.61:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61━━\u001b[0m \u001b[32m19/86\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/86\u001b[0m [nvidia-modelopt-core]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.55━\u001b[0m \u001b[32m23/86\u001b[0m [nvidia-modelopt-core]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.55:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/86\u001b[0m [nvidia-modelopt-core]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.55━━━\u001b[0m \u001b[32m23/86\u001b[0m [nvidia-modelopt-core]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.13.0.11━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.13.0.11:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61━\u001b[0m \u001b[32m24/86\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/86\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57[0m \u001b[32m27/86\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/86\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57━\u001b[0m \u001b[32m27/86\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/86\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.3.14━\u001b[0m \u001b[32m28/86\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.3.14:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/86\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14━━━\u001b[0m \u001b[32m28/86\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: triton[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [typing-inspection]]\n",
      "\u001b[2K    Found existing installation: triton 3.3.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [typing-inspection]\n",
      "\u001b[2K    Uninstalling triton-3.3.1:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [typing-inspection]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [typing-inspection]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/86\u001b[0m [onnx]v-python-headless]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.7.53[0m \u001b[32m52/86\u001b[0m [onnx]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.7.53:━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/86\u001b[0m [onnx]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53━\u001b[0m \u001b[32m52/86\u001b[0m [onnx]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53/86\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.41━━\u001b[0m \u001b[32m53/86\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.41:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53/86\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41━━━━\u001b[0m \u001b[32m53/86\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m54/86\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.7.1.26━━━\u001b[0m \u001b[32m54/86\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.7.1.26:[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m54/86\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.7.1.26━━━━━\u001b[0m \u001b[32m54/86\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m65/86\u001b[0m [pydantic]ce-hub]2]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.2.55━━━\u001b[0m \u001b[32m67/86\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.2.55:m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m67/86\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55━\u001b[0m \u001b[32m67/86\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m69/86\u001b[0m [transformers]er-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.1+cu128\u001b[90m━━━━━━━\u001b[0m \u001b[32m69/86\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torch-2.7.1+cu128:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m70/86\u001b[0m [torch]rs]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1+cu1280m\u001b[90m━━━━━━━\u001b[0m \u001b[32m70/86\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86/86\u001b[0m [tensorrt_llm]orrt_llm]sets]e]python]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.7.1+cu128 requires torch==2.7.1, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed StrEnum-0.4.15 accelerate-1.9.0 aenum-3.1.16 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 async-timeout-5.0.1 backoff-2.2.1 build-1.2.2.post1 click_option_group-0.5.7 colored-2.3.1 cuda-bindings-12.9.0 cuda-python-12.9.0 datasets-3.1.0 diffusers-0.34.0 dill-0.3.8 einops-0.8.1 evaluate-0.4.5 fastapi-0.115.4 flashinfer-python-0.2.5 frozenlist-1.7.0 h5py-3.12.1 hf-xet-1.1.5 huggingface-hub-0.34.3 jiter-0.10.0 mpi4py-4.1.0 multidict-6.6.3 multiprocess-0.70.16 ninja-1.11.1.4 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-modelopt-0.29.0 nvidia-modelopt-core-0.29.0 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 nvtx-0.2.12 onnx-1.18.0 onnx_graphsurgeon-0.5.8 openai-1.98.0 opencv-python-headless-4.11.0.86 optimum-1.27.0 ordered-set-4.1.0 peft-0.16.0 pillow-10.3.0 polygraphy-0.49.26 propcache-0.3.2 protobuf-6.31.1 pulp-3.2.2 pyarrow-21.0.0 pydantic-2.11.7 pydantic-core-2.33.2 pynvml-12.0.0 pyproject_hooks-1.2.0 regex-2025.7.34 safetensors-0.5.3 sentencepiece-0.2.0 setuptools-79.0.1 starlette-0.41.3 tensorrt-10.10.0.31 tensorrt_cu12-10.10.0.31 tensorrt_cu12_bindings-10.10.0.31 tensorrt_cu12_libs-10.10.0.31 tensorrt_llm-0.20.0 tiktoken-0.9.0 tokenizers-0.21.4 torch-2.7.0 torchprofile-0.0.4 tqdm-4.67.1 transformers-4.51.3 triton-3.3.0 typing-extensions-4.14.1 typing-inspection-0.4.1 uvicorn-0.35.0 xgrammar-0.1.16 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "# Optional step: Only required for Blackwell and Grace Hopper\n",
    "!pip3 install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "#!sudo apt-get -y install libopenmpi-dev\n",
    "\n",
    "#Install pre-built TensorRT-LLM wheel\n",
    "!pip3 install --upgrade pip setuptools && pip3 install tensorrt_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f132155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n",
      "<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025-07-31 16:26:09.727971: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 16:26:09.937674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753979170.019845   13573 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753979170.042777   13573 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753979170.212976   13573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979170.213010   13573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979170.213013   13573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979170.213015   13573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-31 16:26:10.233046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 16:26:13,888 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT-LLM] TensorRT-LLM version: 0.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Loading Model: \u001b[1;32m[1/3]\t\u001b[0mDownloading HF model\n",
      "\u001b[38;20mDownloaded model to /home/ubuntu/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6\n",
      "\u001b[0m\u001b[38;20mTime: 12.133s\n",
      "\u001b[0mLoading Model: \u001b[1;32m[2/3]\t\u001b[0mLoading HF model to memory\n",
      "160it [00:00, 1894.24it/s]\n",
      "\u001b[38;20mTime: 0.374s\n",
      "\u001b[0mLoading Model: \u001b[1;32m[3/3]\t\u001b[0mBuilding TRT-LLM engine\n",
      "\u001b[38;20mTime: 32.230s\n",
      "\u001b[0m\u001b[1;32mLoading model done.\n",
      "\u001b[0m\u001b[38;20mTotal latency: 44.738s\n",
      "\u001b[0m\u001b[33;20mrank 0 using MpiPoolSession to spawn MPI processes\n",
      "\u001b[0m<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n",
      "<frozen importlib._bootstrap_external>:1184: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2025-07-31 16:27:05.987587: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-31 16:27:05.998890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753979226.012302   18862 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753979226.016158   18862 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753979226.026081   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979226.026102   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979226.026105   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753979226.026106   18862 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-31 16:27:06.029315: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Multiple distributions found for package optimum. Picked distribution: optimum\n",
      "2025-07-31 16:27:08,586 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT-LLM] TensorRT-LLM version: 0.20.0\n",
      "[TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "[TensorRT-LLM][INFO] Engine version 0.20.0 found in the config file, assuming engine(s) built by new builder API.\n",
      "[TensorRT-LLM][INFO] Refreshed the MPI local session\n",
      "[TensorRT-LLM][INFO] MPI size: 1, MPI local size: 1, rank: 0\n",
      "[TensorRT-LLM][INFO] Rank 0 is using GPU 0\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxNumSequences: 2048\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxBatchSize: 2048\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxBeamWidth: 1\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxSequenceLen: 2048\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxDraftLen: 0\n",
      "[TensorRT-LLM][INFO] TRTGptModel mMaxAttentionWindowSize: (2048) * 22\n",
      "[TensorRT-LLM][INFO] TRTGptModel enableTrtOverlap: 0\n",
      "[TensorRT-LLM][INFO] TRTGptModel normalizeLogProbs: 0\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxNumTokens: 8192\n",
      "[TensorRT-LLM][INFO] TRTGptModel maxInputLen: 2047 = min(maxSequenceLen - 1, maxNumTokens) since context FMHA and usePackedInput are enabled\n",
      "[TensorRT-LLM][INFO] TRTGptModel If model type is encoder, maxInputLen would be reset in trtEncoderModel to maxInputLen: min(maxSequenceLen, maxNumTokens).\n",
      "[TensorRT-LLM][INFO] Capacity Scheduler Policy: GUARANTEED_NO_EVICT\n",
      "[TensorRT-LLM][INFO] Context Chunking Scheduler Policy: None\n",
      "[TensorRT-LLM][INFO] Loaded engine size: 2106 MiB\n",
      "[TensorRT-LLM][INFO] Engine load time 1324 ms\n",
      "[TensorRT-LLM][INFO] Inspecting the engine to identify potential runtime issues...\n",
      "[TensorRT-LLM][INFO] The profiling verbosity of the engine does not allow this analysis to proceed. Re-build the engine with 'detailed' profiling verbosity to get more diagnostics.\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] Allocated 480.01 MiB for execution context memory.\n",
      "[TensorRT-LLM][INFO] gatherContextLogits: 0\n",
      "[TensorRT-LLM][INFO] gatherGenerationLogits: 0\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 2098 (MiB)\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] Allocated 330.16 MB GPU memory for runtime buffers.\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] Allocated 1.16 GB GPU memory for decoder.\n",
      "[TensorRT-LLM][INFO] Memory usage when calculating max tokens in paged kv cache: total: 79.19 GiB, available: 73.78 GiB, extraCostMemory: 0.00 GiB\n",
      "[TensorRT-LLM][INFO] Number of blocks in KV cache primary pool: 98903\n",
      "[TensorRT-LLM][INFO] Number of blocks in KV cache secondary pool: 0, onboard blocks to primary memory before reuse: true\n",
      "[TensorRT-LLM][INFO] before Create KVCacheManager cacheTransPreAllocaSize:0\n",
      "[TensorRT-LLM][INFO] Max KV cache pages per sequence: 64 [window size=2048]\n",
      "[TensorRT-LLM][INFO] Number of tokens per block: 32.\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] Allocated 66.40 GiB for max tokens in paged KV cache (3164896).\n"
     ]
    }
   ],
   "source": [
    "from tensorrt_llm import LLM, SamplingParams\n",
    "llm = LLM(model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac61281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed requests:   0%|          | 0/2 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/tensorrt_llm/llmapi/utils.py:424: UserWarning: LLM API is running in async mode because you have a running event loop, but you are using sync API. This may lead to potential performance loss.\n",
      "  warnings.warn(\n",
      "Processed requests: 100%|██████████| 2/2 [00:00<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'Hello, my name is', Generated text: 'John Smith. I am a student at this university. I am studying computer science. Do you have any recommendations for internships or summer programs that would be'\n",
      "Prompt: 'The capital of France is', Generated text: 'located in the Loire Valley, France. Tourism is a significant industry in France, with more than 150 million visitors annually. One of'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"Hello, my name is\", \"The capital of France is\"]\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "for output in llm.generate(prompts, sampling_params):\n",
    "    print(f\"Prompt: {output.prompt!r}, Generated text: {output.outputs[0].text!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c26730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
